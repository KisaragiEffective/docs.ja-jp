---
title: クラウド ネイティブの定義
description: クラウドネイティブ システムの基盤を提供する基本的な柱について説明します。
author: robvet
ms.date: 01/19/2021
ms.openlocfilehash: 180b32d753fea5071174830be4ff3b8a81527a75
ms.sourcegitcommit: f2ab02d9a780819ca2e5310bbcf5cfe5b7993041
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 02/03/2021
ms.locfileid: "99506215"
---
# <a name="defining-cloud-native"></a>クラウド ネイティブの定義

作業していることを止めて、10 人の同僚にメールを送ってください。 "クラウド ネイティブ" という用語を定義してもらいます。 高い確率で 10 個の異なる答えが返ってくるでしょう。

クラウド ネイティブでは、重要なビジネス システムの構築についての考え方が変わります。

クラウドネイティブ システムは、迅速な変更、大規模、および回復力を包含するように設計されます。

Cloud Native Computing Foundation によって、[公式の定義](https://github.com/cncf/foundation/blob/master/charter.md)が提供されています。

> *クラウドネイティブ テクノロジは、パブリック クラウド、プライベート クラウド、ハイブリッド クラウドなどの近代的でダイナミックな環境において、スケーラブルなアプリケーションを構築および実行するための能力を組織にもたらします。このアプローチの代表例には、コンテナー、サービス メッシュ、マイクロサービス、イミュータブル インフラストラクチャ、および宣言型 API があります。*

> *これらの手法により、回復性、管理力、および可観測性のある疎結合システムが実現します。これらを堅牢な自動化と組み合わせることで、インパクトのある変更を最小限の労力で頻繁かつ予測どおりに行うことができます。*

アプリケーションがますます複雑になり、それに伴い、ユーザーの要求はさらに高まっています。 ユーザーは、迅速な応答性、革新的な機能、ダウンタイム ゼロを期待します。 パフォーマンスの問題、繰り返し発生するエラー、および機敏に動けないことは、許容されなくなりました。 たやすく競合他社に乗り換えられます。

クラウドネイティブでは、"*スピード*" と "*機敏性*" が重要です。 ビジネス システムは、ビジネスの能力を実現することから、ビジネスのスピードと成長を加速させる戦略的変革のための武器になることへと進化しています。 すぐに市場に投入できるアイデアを得ることが不可欠です。

ここでは、このような手法を実装した企業をいくつか紹介します。 実現された、スピード、機敏性、およびスケーラビリティについて考えてみましょう。

| [会社] | エクスペリエンス |
| :-------- | :-------- |
| [Netflix](https://www.infoq.com/news/2013/06/netflix/) | 600 を超えるサービスを運用環境で提供しています。 配置回数は 1 日あたり 100 回です。 |
| [Uber](https://eng.uber.com/micro-deploy/) | 1,000 を超えるサービスを運用環境で提供しています。 配置回数は週あたり数千回です。 |
| [WeChat](https://www.cs.columbia.edu/~ruigu/papers/socc18-final100.pdf) | 3,000 を超えるサービスを運用環境で提供しています。 配置回数は 1 日あたり 1000 回です。 |

ご覧のように、Netflix、Uber、WeChat は、数百の独立したマイクロサービスで構成されるシステムを公開しています。 このアーキテクチャ スタイルによって、市場の状況に迅速に対応できます。 稼働中の複雑なアプリケーションの小さな部分を即時に更新し、必要に応じてそれらの部分を個別にスケールできます。

クラウドネイティブのスピードと機敏性は、いくつもの要因によって生まれます。 最も重要なのはクラウド インフラストラクチャです。 図 1-3 に示す、その他 5 つの基本な柱によっても、クラウドネイティブ システムの基盤が提供されます。

![クラウドネイティブの基本的な柱](./media/cloud-native-foundational-pillars.png)

**図 1-3**. クラウドネイティブの基本的な柱

それぞれの柱の重要性をよく理解できるように、もう少し時間を取ってみましょう。

## <a name="the-cloud"></a>クラウド…

クラウドネイティブ システムは、クラウド サービス モデルを最大限に活用します。

これらのシステムは、仮想化された動的なクラウド環境で効果を発揮するように設計され、[サービスとしてのプラットフォーム (PaaS)](https://azure.microsoft.com/overview/what-is-paas/) コンピューティング インフラストラクチャおよび管理対象サービスを全面的に使用しています。 基礎となるインフラストラクチャは "*ディスポーザブル*" として扱われます。つまり、自動化を介して、数分間でプロビジョニングされ、オンデマンドでサイズ変更、スケール、移動、または破棄が行われます。

広く受け入れられている DevOps の[ペットと家畜](https://medium.com/@Joachim8675309/devops-concepts-pets-vs-cattle-2380b5aab313)の概念を考えてみましょう。 従来のデータ センターでは、サーバーは "*ペット*" として扱われます。つまり、わかりやすい名前が付けられて大切にされる物理マシンです。 同じマシンにリソースを追加してスケールします (スケールアップ)。 サーバーに不具合が生じると、正常に戻すために対処します。 サーバーが使用できなくなると、だれもが気付きます。

"*家畜*" のサービス モデルは異なります。 各インスタンスは、仮想マシンまたはコンテナーとしてプロビジョニングされます。 これらはまったく同じであり、Service-01 や Service-02 のようなシステム識別子が割り当てられます。 さらに作成することでスケールします (スケールアウト)。 1 つが使用できなくなっても、だれも気付きません。

家畜モデルでは、"*イミュータブル インフラストラクチャ*" が採用されます。 サーバーの修復や変更は行われません。 障害が発生したり更新が必要になったりすると、破棄され、新しいものがプロビジョニングされます。すべて自動化されています。

クラウドネイティブ システムは、家畜サービス モデルを採用しています。 実行を続ける際に、インフラストラクチャはスケールインまたはスケールアウトしますが、どのマシンで実行しているかは関係ありません。

Azure クラウド プラットフォームでは、自動スケーリング、自己復旧、監視機能を備えた、このようなきわめてエラスティックなインフラストラクチャがサポートされています。

## <a name="modern-design"></a>モダン デザイン

クラウドネイティブ アプリはどのように設計すればよいでしょうか。 アーキテクチャはどのようになりますか。 遵守するのは、どのような原則、パターン、およびベスト プラクティスですか。 インフラストラクチャおよび運用に関する重要な考慮事項は何でしょうか。

### <a name="the-twelve-factor-application"></a>Twelve-Factor Application

クラウドベース アプリケーションの構築方法として広く受け入れられているのが [Twelve-Factor Application](https://12factor.net/) です。 ここでは、最新のクラウド環境向けに最適化されたアプリケーションを構築するために、開発者が従う一連の原則およびプラクティスについて説明します。 環境間の移植性と宣言型の自動化に、特に注意が払われています。

あらゆる Web ベース アプリケーションにも当てはまりますが、多くの専門家は、Twelve-Factor をクラウドネイティブ アプリを構築するための堅固な基盤と見なしています。 これらの原則に基づいて構築されたシステムでは、配置とスケールを機敏に行うことができ、市場の変化に迅速に対応して機能を追加できます。

次の表に、Twelve-Factor 方法論を示します。

|    |  要因 | 説明  |
| :-------- | :-------- | :-------- |
| 1 | コード ベース | 各マイクロサービスの 1 つのコード ベースが、独自のリポジトリに格納されています。 バージョン管理によって追跡され、複数の環境 (QA、ステージング、運用環境) に配置できます。 |
| 2 | 依存関係 | 各マイクロサービスでは、それぞれの依存関係を分離してパッケージ化し、システム全体に影響を与えずに変更を行います。 |
| 3 | 構成  | 構成情報は、マイクロサービスから取り出され、コード外部の構成管理ツールを使用して外部化されます。 同じ配置が、正しい構成の適用により、複数の環境に伝達されます。  |
| 4 | 補助的サービス | 補助リソース (データ ストア、キャッシュ、メッセージ ブローカー) をアドレス指定可能な URL を介して公開する必要があります。 これによって、アプリケーションからリソースが分離され、交換可能になります。  |
| 5 | ビルド、リリース、実行 | リリースごとに、ビルド、リリース、および実行の各ステージに対して厳密な分離を適用する必要があります。 それぞれに一意の ID をタグ付けし、ロールバックできる機能をサポートする必要があります。 最新の CI/CD システムは、この原則に従うのに役立ちます。 |
| 6 | 処理 | 各マイクロサービスは、実行中の他のサービスから分離され、独自のプロセス内で実行する必要があります。 必要な状態を、補助的サービス (分散キャッシュまたはデータ ストア) に外部化します。 |
| 7 | [ポートのバインド] | 各マイクロサービスは、独自のポートで公開されるインターフェイスと機能を含めて、自己完結している必要があります。 これによって、他のマイクロサービスから分離されます。 |
| 8 | コンカレンシー | サービスは、使用可能な最高性能のマシン上で 1 つの大きなインスタンスをスケールアップするのではなく、多数の小さな同一プロセス (コピー) に対してスケールアウトします。 |
| 9 | ディスポーザビリティ | サービス インスタンスはディスポーザブルであることが必要です。これにより、高速で起動してスケーラビリティの機会を増やし、正常にシャットダウンしてシステムを適切な状態に保つことができます。 Docker コンテナーおよびオーケストレーターによって、本質的にこの要件が満たされます。 |
| 10 | 開発/運用のパリティ | 環境をアプリケーション ライフサイクル全体で可能な限り同様に維持し、コストのかかるショートカットを回避します。 ここでは、コンテナーの採用が大きく貢献します。同じ実行環境が推進されるためです。 |
| 11 | ログの記録 | マイクロサービスによって生成されるログをイベント ストリームとして扱います。 イベント アグリゲーターを使用して処理し、データをデータマイニング/ログ管理ツール (Azure Monitor や Splunk など) に伝達し、最終的には長期間アーカイブを行います。 |
| 12 | 管理プロセス | 管理タスクを 1 回限りのプロセスとして実行します。 タスクには、レポートのためのデータ クリーンアップとプル分析が含まれることがあります。 これらのタスクを実行するツールは、運用環境から呼び出す必要がありますが、アプリケーションとは別に呼び出します。 |

『[Beyond the Twelve-Factor App](https://content.pivotal.io/blog/beyond-the-twelve-factor-app)』(Twelve-Factor App の先に) で、著者 Kevin Hoffman は本来の 12 個の要因それぞれを詳しく説明しています (2011 年)。 さらに、現在の最新クラウド アプリケーション設計を反映する追加の 3 つの要因についても述べています。

|    |  新しい要因 | 説明  |
| :-------- | :-------- | :-------- |
| 13 | API ファースト | すべてをサービスにします。 コードが、フロントエンド クライアント、ゲートウェイ、または別のサービスによって使用される仮定します。 |
| 14 | 製品利用統計情報 | ワークステーション上で、アプリケーションとその動作の詳細を確認します。 クラウドでは、行いません。 監視、ドメイン固有、および正常性/システム データのコレクションが設計に含まれていることを確認します。 |
| 15 | 認証/承認  | 最初から ID を実装します。 パブリック クラウドでは、使用可能な [RBAC (ロールベースのアクセス制御)](/azure/role-based-access-control/overview) 機能を検討してください。  |

この章および全体を通して、12 個および追加の要因の多くを紹介します。

### <a name="critical-design-considerations"></a>設計に関する重要な考慮事項

Twelve-Factor 方法論から得られるガイダンス以外に、分散システムを構築する際には、重要な設計上の決定をいくつか行う必要があります。

*通信*

フロントエンド クライアント アプリケーションは、どのようにバックエンド コア サービスと通信しますか。 直接通信を許可しますか。 または、柔軟性、制御、およびセキュリティを提供するゲートウェイ ファサードを使用して、バックエンド サービスを抽象化しますか。

バックエンド コア サービスはどのように相互に通信しますか。 直接 HTTP 呼び出しを許可しますか (これは結合につながり、パフォーマンスと機敏性に影響があります)。 または、キューやトピックのテクノロジを使用してメッセージングを切り離すことを検討しますか。

通信の詳細については、第 4 章「*クラウドネイティブの通信パターン*」を参照してください。

*回復性*

マイクロサービス アーキテクチャによって、インプロセスからアウトプロセス ネットワーク通信にシステムが移行されます。 分散アーキテクチャで、サービス B がサービス A からのネットワーク呼び出しに応答しないと、何が発生しますか。 また、サービス C が一時的に使用できなくなり、それを呼び出す他のサービスがブロックされた場合、どうなりますか。

回復性については、第 6 章「*クラウドネイティブの回復性*」を参照してください。

"*分散データ*"

仕様では、各マイクロサービスは自らのデータをカプセル化し、パブリック インターフェイスを介して操作を公開します。 この場合、複数のサービスにわたって、データを照会したり、トランザクションを実装したりするにはどうすればよいでしょうか。

分散データの詳細については、第 5 章「*クラウドネイティブのデータ パターン*」を参照してください。

*ID*

サービスでは、アクセスしているユーザーとそのアクセス許可はどのように識別されますか。

ID の詳細については、第 8 章「*ID*」を参照してください。

## <a name="microservices"></a>マイクロサービス

クラウドネイティブ システムは、最新のアプリケーションを構築するための一般的なアーキテクチャ スタイルであるマイクロサービスを採用しています。

共有ファブリックを介してやり取りする、独立した小さいサービスの分散セットとして構築されたマイクロサービスは、次の特性を共有します。

- それぞれは、より大きなドメインのコンテキストにおいて、特定のビジネス機能を実装します。

- それぞれは、自律的に開発され、独立して配置できます。

- それぞれは、独自のデータ ストレージ テクノロジ (SQL、NoSQL) およびプログラミング プラットフォームを自己完結型でカプセル化しています。

- それぞれは、独自のプロセス内で実行し、標準通信プロトコル (HTTP/HTTPS、WebSockets、[AMQP](https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol) など) を使用して他と通信します。

- これらがまとまって、1 つのアプリケーションを形成します。

図 1-4 は、モノリシック アプリケーション アプローチとマイクロサービス アプローチを比較したものです。 モノリスは 1 つのプロセスで実行される多層アーキテクチャで構成されていることに注意してください。 通常、リレーショナル データベースが使用されます。 ただし、マイクロサービス アプローチでは、機能が独立したサービスに分離され、それぞれにロジックとデータが含まれています。 各マイクロサービスが独自のデータストアをホストします。

![モノリシック配置とマイクロサービス](./media/monolithic-vs-microservices.png)

**図 1-4.** モノリシック配置とマイクロサービス

マイクロサービスによって、この章で前述した [Twelve-Factor Application](https://12factor.net/) の "1 つのコードベース、1 つのアプリケーション" の原則がどのように推進されているかに注意してください。

> "*要因 \#1 の指定: "各マイクロサービスの 1 つのコード ベースが、独自のリポジトリに格納されています。バージョン管理によって追跡され、複数の環境に配置できます。"* "

### <a name="why-microservices"></a>マイクロサービスについて

マイクロサービスによって機敏性が提供されます。

この章の前半では、モノリスとして構築された e コマース アプリケーションを、マイクロサービスを使用したものと比較しました。 この例では、明確な利点がいくつかわかりました。

- 各マイクロサービスには自律したライフサイクルがあり、個別に進化することができ、頻繁に配置できます。 新しい機能の配置または更新のために、四半期ごとのリリースを待つ必要はありません。 複雑なアプリケーションの小さな部分を更新することができ、システム全体を中断させるリスクは軽減します。

- 各マイクロサービスは個別にスケールできます。 アプリケーション全体を 1 つのユニットとしてスケールアウトするのではなく、より多くの処理能力やネットワーク帯域幅を必要とするサービスのみをスケールアウトします。 このように細分化されたスケールのアプローチによって、システムをより細かく制御できるようになり、システム全体ではなくシステムの一部をスケールすることで全体的なコストを削減することができます。

マイクロサービスを理解するための優れた参照ガイドとして、『[.NET Microservices: Architecture for Containerized .NET Applications](https://dotnet.microsoft.com/download/thank-you/microservices-architecture-ebook)』(.NET マイクロサービス: コンテナー化された .NET アプリケーションのアーキテクチャ) をお勧めします。 この本は、マイクロサービスの設計とアーキテクチャについて深く掘り下げています。 これは、Microsoft から無料でダウンロードできる[フルスタック マイクロサービス リファレンス アーキテクチャ](https://github.com/dotnet-architecture/eShopOnContainers)の手引きです。

### <a name="developing-microservices"></a>マイクロサービスの開発

マイクロサービスは、どの最新開発プラットフォームを使用しても作成できます。

Microsoft .NET プラットフォームは最適な選択です。 無料かつオープンソースであり、マイクロサービスの開発を簡易化する組み込み機能が多数用意されています。 .NET はクロスプラットフォームです。 Windows、macOS、およびほとんどの Linux に対して、アプリケーションをビルドして実行できます。

.NET は非常に高いパフォーマンスを備え、Node.js およびその他の競合プラットフォームとの比較でも高く評価されています。 興味深いのですが、[TechEmpower](https://www.techempower.com/) によって、多数の Web アプリケーション プラットフォームおよびフレームワークで広範囲の[パフォーマンス ベンチマーク](https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=plaintext)が測定されました。 .NET は上位 10 までに入り、Node.js や他の競合プラットフォームを引き離しました。

.NET は、Microsoft および GitHub 上の .NET コミュニティによって管理されています。

## <a name="containers"></a>Containers

現在、"*クラウドネイティブ*" に関するあらゆる会話で "*コンテナー*" という用語を耳にするのは自然です。 『[Cloud Native Patterns](https://www.manning.com/books/cloud-native-patterns)』(クラウド ネイティブ パターン) の著者 Cornelia Davis は、"コンテナーはクラウドネイティブ ソフトウェアの大きな成功要因である" と見ています。 Cloud Native Computing Foundation は、マイクロサービスのコンテナー化を[クラウドネイティブ トレイル マップ](https://raw.githubusercontent.com/cncf/trailmap/master/CNCF_TrailMap_latest.png) (クラウドネイティブ体験を始める企業向けのガイダンス) の最初のステップと位置付けています。

マイクロサービスのコンテナー化はシンプルで簡単です。 コード、その依存関係、およびランタイムが、[コンテナー イメージ](https://docs.docker.com/glossary/?term=image)と呼ばれるバイナリにパッケージ化されます。 イメージは、イメージのリポジトリまたはライブラリとして機能する[コンテナー レジストリ](https://caylent.com/container-registries/)に格納されます。 レジストリは、開発用コンピューター、データ センター、またはパブリック クラウドに配置できます。 Docker 自体は、[Docker Hub](https://hub.docker.com/) を使用してパブリック レジストリを管理します。 Azure クラウドには[コンテナー レジストリ](https://azure.microsoft.com/services/container-registry/)があり、実行するクラウド アプリケーションの近くにコンテナー イメージが格納されます。

必要な場合には、イメージを実行コンテナー インスタンスに変換します。 インスタンスは、[コンテナー ランタイム](https://kubernetes.io/docs/setup/production-environment/container-runtimes/) エンジンがインストールされている任意のコンピューター上で実行されます。 コンテナー化されたサービスのインスタンスは、必要に応じていくつでも作成できます。

図 1-5 は、 3 つの異なるマイクロサービスがそれぞれのコンテナーにあり、1 つのホストで実行されていることを示しています。

![コンテナー ホストで実行されている複数のコンテナー](./media/hosting-mulitple-containers.png)

**図 1-5**. コンテナー ホストで実行されている複数のコンテナー

各コンテナーが独自の依存関係とランタイムのセット (異なる可能性がある) をどのように保持しているかに注意してください。 ここで、異なるバージョンの Product マイクロサービスが同一ホスト上で実行していることに気付きます。 各コンテナーは、基礎となるホスト オペレーティング システム、メモリ、およびプロセッサのスライスを共有しますが、互いに分離しています。

このコンテナー モデルが [Twelve-Factor Application](https://12factor.net/) の "依存関係" の原則をどのように適切に採用しているかに注意してください。

> "*要因 \#2 の指定: "各マイクロサービスでは、それぞれの依存関係を分離してパッケージ化し、システム全体に影響を与えずに変更を行います。"* "

コンテナーでは、Linux と Windows 両方のワークロードがサポートされます。 Azure クラウドでは両方が包含されています。 興味深いことですが、Azure で最も一般的なオペレーティング システムになっている Windows Server ではなく Linux です。

複数のコンテナー ベンダーが存在しているものの、Docker が最大の市場シェアを獲得しています。 この企業はソフトウェア コンテナーの動向を推進してきました。 クラウドネイティブ アプリケーションのパッケージ化、配置、実行のための事実上の標準になっています。

### <a name="why-containers"></a>コンテナーについて

コンテナーによって、環境間での移植性が提供され、一貫性が保証されます。 すべてを 1 つのパッケージにカプセル化することで、マイクロサービスとその依存関係を、基礎となるインフラストラクチャから "*分離*" します。

Docker ランタイム エンジンがあるすべての環境に同じコンテナーを配置できます。 コンテナー化されたワークロードでは、フレームワーク、ソフトウェア ライブラリ、およびランタイム エンジンによって各環境を事前に構成するコストも不要になります。

基礎となるオペレーティング システムとホスト リソースを共有することで、コンテナーのフットプリントは、完全な仮想マシンよりもかなり小さくなります。 サイズが小さくなると、特定のホストが一度に実行できる "*密度*" (マイクロサービスの数) が増加します。

### <a name="container-orchestration"></a>コンテナーのオーケストレーション

Docker などのツールによって、イメージの作成やコンテナーの実行が行われますが、それらを管理するツールも必要です。 コンテナー管理は、コンテナー オーケストレーターと呼ばれる特別なソフトウェア プログラムを使用して行われます。 大規模に運用する場合は、コンテナー オーケストレーションが不可欠です。

図 1-6 は、コンテナー オーケストレーターによって提供される管理タスクを示しています。

![コンテナー オーケストレーターが行うこと](./media/what-container-orchestrators-do.png)

**図 1-6**. コンテナー オーケストレーターが行うこと

次の表では、一般的なオーケストレーション タスクについて説明します。

|  タスク | 説明  |
| :-------- | :-------- |
| スケジュール設定 | コンテナー インスタンスを自動的にプロビジョニングします。|
| アフィニティ/アンチアフィニティ | 隣接しているコンテナーまたは相互に遠く離れたコンテナーをプロビジョニングし、可用性とパフォーマンスを高めます。 |
| 正常性の監視 | エラーを自動的に検出して修正します。|
| [フェールオーバー] | 失敗したインスタンスを正常なコンピューターに自動的に再プロビジョニングします。|
| スケーリング | 需要に合わせて、コンテナー インスタンスを自動的に追加または削除します。|
| ネットワーク | コンテナー通信のネットワーク オーバーレイを管理します。|
| サービス探索 | コンテナーが互いを見つけられるようにします。|
| ローリング アップグレード | ダウンタイム ゼロの配置を使用して増分アップグレードを調整します。 問題のある変更を自動的にロールバックします。|

オーケストレーターによって、この章で前述した [Twelve-Factor Application](https://12factor.net/) のディスポーザビリティとコンカレンシーの原則がどのように採用されているかに注意してください。

> "*要因 \#9 の指定: "サービス インスタンスはディスポーザブルであることが必要です。これにより、高速で起動してスケーラビリティの機会を増やし、正常にシャットダウンしてシステムを適切な状態に保つことができます。Docker コンテナーおよびオーケストレーターによって、本質的にこの要件が満たされます。"* "

> "*要因 \#8 の指定: "サービスは、使用可能な最高性能のマシン上で 1 つの大きなインスタンスをスケールアップするのではなく、多数の小さな同一プロセス (コピー) に対してスケールアウトします。"* "

いくつかのコンテナー オーケストレーターが存在していますが、クラウドネイティブの世界で事実上の標準となったのは [Kubernetes](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/) です。 これは、コンテナー化されたワークロードを管理するための、移植可能で拡張可能なオープンソース プラットフォームです。

独自の Kubernetes インスタンスをホストすることもできますが、そうするとリソースのプロビジョニングと管理に責任を持つことになり、複雑になる可能性があります。 Azure クラウドでは、Kubernetes が管理サービス [Azure Kubernetes Service (AKS)](https://azure.microsoft.com/services/kubernetes-service/) として提供されます 管理サービスを使用すると、インストールや保守を行う必要なしに、機能を完全に活用できます。

Azure Kubernetes Services の詳細については、第2章「*クラウドネイティブ アプリケーションのスケール*」を参照してください。

## <a name="backing-services"></a>補助的サービス

クラウドネイティブ システムは、データ ストア、メッセージ ブローカー、監視、ID サービスなど、さまざまな補助リソースに依存しています。 これらのサービスは、[補助的サービス](https://12factor.net/backing-services)と呼ばれています。

 図 1-7 は、クラウドネイティブ システムが使用する多くの一般的な補助的サービスを示しています。

![一般的な補助的サービス](./media/common-backing-services.png)

**図 1-7**. 一般的な補助的サービス

補助的サービスによって、この章で前述した [Twelve-Factor Application](https://12factor.net/) の "ステートレス" の原則が推進されます。

>"*要因 \#6*" の指定: "各マイクロサービスは、実行中の他のサービスから分離され、独自のプロセス内で実行する必要があります。 必要な状態を、補助的サービス (分散キャッシュまたはデータ ストア) に外部化します。"

独自の補助的サービスをホストすることもできますが、その場合は、それらのリソースのライセンス、プロビジョニング、および管理を行う必要があります。

クラウド プロバイダーでは、"*管理された補助的サービス*" の豊富な組み合わせが提供されます。 サービスを所有するのではなく、ただ使用します。 プロバイダーは大規模にリソースを運用し、パフォーマンス、セキュリティ、およびメンテナンスの責任を負います。 監視、冗長性、可用性は、サービスに組み込まれています。 プロバイダーによって管理サービスは完全にサポートされています。チケットをオープンすると、問題が解決されます。

クラウドネイティブ システムでは、クラウド ベンダーの管理された補助的サービスが優先されます。 時間と労力が大幅に節約されます。 独自にホストしてトラブルが発生する運用リスクにより、すぐにコストが増加する可能性があります。

ベスト プラクティスは、補助的サービスを "*アタッチされるリソース*" として扱い、外部構成に格納された情報 (URL および資格情報) を使用して、動的にマイクロサービスにバインドすることです。 このガイダンスは、この章で前述した [Twelve-Factor Application](https://12factor.net/) で詳しく説明されています。

>"*要因 \#4*" の指定: 補助的サービスは "アドレス指定可能な URL を介して公開する必要があります。 これによって、アプリケーションからリソースが分離され、交換可能になります。"

>"*要因 \#3*" の指定: "構成情報は、マイクロサービスから取り出され、コード外部の構成管理ツールを使用して外部化されます。"

このパターンを使用すると、コードを変更せずに、補助的サービスをアタッチおよびデタッチできます。 マイクロサービスを QA からステージング環境に進める場合があります。 ステージング環境の補助的サービスを指すようにマイクロサービスの構成を更新し、その設定を環境変数を使用してコンテナーに挿入します。

クラウド ベンダーによって、独自の補助的サービスと通信するための API が提供されます。 これらのライブラリでは、プラミングと複雑さがカプセル化されています。 これらの API と直接通信することで、コードと補助的サービスが密接に結合されます。 ベンダー API の実装の詳細を分離することをお勧めします。 中間層 (中間 API) を導入して、汎用的な処理をサービス コードに公開します。 このような疎結合によって、メインのサービス コードに変更を加える必要なしに、補助的サービスを切り替えたり、コードを別のパブリック クラウドに移したりできるようになります。

補助的サービスの詳細については、第 5 章「*クラウドネイティブのデータ パターン*」および第 4 章「*クラウドネイティブの通信パターン*」を参照してください。

## <a name="automation"></a>オートメーション

これまで見てきたように、クラウドネイティブ システムでは、スピードと機敏性を実現するために、マイクロサービス、コンテナー、最新のシステム設計が採用されています。 しかしそれは、ストーリーの一部にすぎません。 これらのシステムの実行基盤となるクラウド環境をどのようにプロビジョニングすればよいでしょうか。 アプリの機能と更新プログラムを迅速に配置するにはどうすればよいでしょうか。 全体を仕上げるにはどうすればよいでしょうか。

広く受け入れられてるプラクティス、[Infrastructure as Code](/azure/devops/learn/what-is-infrastructure-as-code) (IaC) を取り入れます。

IaC を使用して、プラットフォームのプロビジョニングとアプリケーションの配置を自動化できます。 基本的には、テストやバージョン管理などのソフトウェア エンジニアリング プラクティスを、DevOps プラクティスに適用します。 インフラストラクチャと配置は、自動化され、一貫した、反復可能なものになります。

### <a name="automating-infrastructure"></a>インフラストラクチャの自動化

[Azure Resource Manager](/azure/azure-resource-manager/management/overview)、Terraform、[Azure CLI](/cli/azure/) などのツールを使用すると、必要なクラウド インフラストラクチャを宣言によってスクリプト化できます。 リソース名、場所、容量、およびシークレットは、パラメーター化され、動的になります。 スクリプトがバージョン管理され、プロジェクトの成果物としてソース管理にチェックインされます。 スクリプトを呼び出して、一貫性のある反復可能なインフラストラクチャを、システム環境全体 (QA、ステージング、運用など) にプロビジョニングします。

内部では IaC はべき等です。つまり、同じスクリプトを何度も実行しても副作用がありません。 チームが変更を加える必要がある場合、スクリプトを編集して再実行します。 更新されたリソースのみが影響を受けます。

記事「[コードとしてのインフラストラクチャとは](/azure/devops/learn/what-is-infrastructure-as-code)」の中で、執筆者 Sam Guckenheimer は次のように説明しています。"IaC を導入するチームは、安定した環境を迅速かつ大規模に実現できます。 チームは、コードによって環境の望ましい状態を表すことで、環境の手動構成を回避し、一貫性を確保します。 IaC を使用したインフラストラクチャのデプロイは反復可能であり、構成ドリフトや依存関係の不足によって発生するランタイムの問題を防止します。 DevOps チームは、統合された一連のプラクティスおよびツールを使用して連携し、アプリケーションとそれを支えるインフラストラクチャを迅速、確実、大規模に実現できます。"

### <a name="automating-deployments"></a>配置の自動化

前述した [Twelve-Factor Application](https://12factor.net/) では、完成したコードを実行中のアプリケーションに変換する際に個別のステップが求められます。

> "*要因 \#5*" の指定: "リリースごとに、ビルド、リリース、および実行の各ステージに対して厳密な分離を適用する必要があります。 それぞれに一意の ID をタグ付けし、ロールバックできる機能をサポートする必要があります。"

最新の CI/CD システムは、この原則に従うのに役立ちます。 個別の配置ステップが提供され、ユーザーがすぐに利用できる一貫性のある高品質のコードが保証されます。

図 1-8 は、配置プロセスにおける分離を示しています。

![CI/CD パイプラインでの配置ステップ](./media/build-release-run-pipeline.png)

**図 1-8**. CI/CD パイプラインでの配置ステップ

前の図で、タスクの分離に特に注意を向けてください。

開発者は、"内部ループ" と呼ばれる、コード、実行、デバッグを繰り返して、開発環境で機能を構築します。 完成すると、そのコードは GitHub、Azure DevOps、BitBucket などのコード リポジトリに "*プッシュ*" されます。

プッシュによって、コードをバイナリの成果物に変換するビルド ステージがトリガーされます。 この作業は[継続的インテグレーション (CI)](https://martinfowler.com/articles/continuousIntegration.html) パイプラインによって実装されます。 これにより、アプリケーションのビルド、テスト、およびパッケージ化が自動的に行われます。

リリース ステージでは、バイナリ成果物が選択され、外部のアプリケーションと環境の構成情報が適用され、イミュータブル リリースが生成されます。 リリースが、指定された環境に配置されます。 この作業は、[継続的デリバリー (CD)](https://martinfowler.com/bliki/ContinuousDelivery.html) パイプラインによって実装されます。 各リリースを識別できる必要があります。 "この配置では、アプリケーションのリリース 2.1.1 を実行しています。" と言うことができます。

最終的に、リリースされた機能がターゲットの実行環境で実行されます。 リリースはイミュータブルです。つまり、どのように変更する場合でも新しいリリースを作成する必要があります。

このようなプラクティスを適用することで、組織はソフトウェアの配布方法を大きく進化させることができました。 多くが、四半期ごとのリリースからオンデマンド更新に移行しました。 目標は、修正コストを下げるために、開発サイクルの早い段階で問題を発見することです。 統合の間隔が広くなるほど、問題の解決にかかるコストが上がります。  統合プロセスの一貫性により、チームはコードの変更を頻繁にコミットできるようになり、コラボレーションとソフトウェアの品質が向上します。

### <a name="azure-pipelines"></a>Azure Pipelines

Azure クラウドには、[Azure Pipelines](https://azure.microsoft.com/services/devops/pipelines/) という新しい CI/CD サービスが含まれます。これは、図 1-9 に示す [Azure DevOps](https://azure.microsoft.com/services/devops/) オファリングに含まれています。

![DevOps の Azure Pipelines](./media/devops-components.png)

**図 1-9**. Azure DevOps オファリング

Azure Pipelines は、継続的インテグレーション (CI) と継続的デリバリー (CD) を組み合わせたクラウド サービスです。 コードのテスト、ビルド、および任意のターゲットへの配布を、自動的に行うことができます。

アプリのその他のコードと共に、YAML ファイルでコードにパイプラインを定義します。

- パイプラインは、コードと共にバージョン管理され、同じ分岐構造に従います。
- プル要求とブランチ ビルド ポリシーでコード レビューにより変更の検証が行われます。
- 使用するすべての分岐が、azure-pipelines.yml ファイルを変更して、ビルド ポリシーをカスタマイズできます。
- パイプライン ファイルはバージョン管理にチェックインされ、問題がある場合は調査できます。

Azure Pipelines サービスではほとんどの Git プロバイダーがサポートされます。また、作成されたアプリケーションの Linux、macOS、または Windows プラットフォームへの配置パイプラインを生成できます。 Java、.NET、JavaScript、Python、PHP、Go、XCode、および C++ のサポートが含まれます。

>[!div class="step-by-step"]
>[前へ](introduction.md)
>[次へ](candidate-apps.md)
